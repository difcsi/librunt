#ifndef LIBRUNT_DSO_META_H_
#define LIBRUNT_DSO_META_H_

#include <sys/time.h>
#include <elf.h>
#include <dlfcn.h>
#ifdef __cplusplus
extern "C" {
#endif
#include <link.h> /* for ElfW() */
#ifdef __cplusplus
}
#endif
#ifdef __cplusplus
#include <cstdbool>
#endif
#include "bitmap.h"
void abort(void) __attribute__((noreturn)); /* keep dependencies down */

union sym_or_reloc_rec;
struct segment_metadata
{
	unsigned phdr_idx;
	union sym_or_reloc_rec *metavector; /* addr-sorted list of relevant dynsym/symtab/extrasym/reloc entries */
	size_t metavector_size;
	bitmap_word_t *starts_bitmap; // maybe!
};

/* Hmm -- with -Wl,-q we might get lots of reloc section mappings. Is this enough? */
#define MAPPING_MAX 16
struct file_metadata
{
	const char *filename;
	const void *load_site;
	struct link_map *l;

	void *meta_obj_handle; /* loaded by us */
	ElfW(Sym) *extrasym;

	ElfW(Phdr) *phdrs; /* always mapped or copied by ld.so */
	ElfW(Half) phnum;
	unsigned nload; /* number of segments that are LOADs */

	ElfW(Sym) *dynsym; /* always mapped by ld.so */
	unsigned char *dynstr; /* always mapped by ld.so */
	unsigned char *dynstr_end;

	ElfW(Half) dynsymndx; // section header idx of dynsym, or 0 if none such
	ElfW(Half) dynstrndx;

	struct extra_mapping
	{
		void *mapping_pagealigned;
		off_t fileoff_pagealigned;
		size_t size;
	} extra_mappings[MAPPING_MAX];

	ElfW(Ehdr) *ehdr;
	ElfW(Shdr) *shdrs;
	unsigned char *shstrtab;
	ElfW(Sym) *symtab; // NOTE this really is symtab, not dynsym
	ElfW(Half) symtabndx;
	unsigned char *strtab; // NOTE this is strtab, not dynstr
	ElfW(Half) strtabndx;

#if 0
	struct allocsites_vectors_by_base_id_entry *allocsites_info;
	struct frame_allocsite_entry *frames_info;
	unsigned nframes;
#endif
	/* "Starts" are symbols with length (spans).
	   We don't index symbols that are not spans.
	   If we see multiple spans covering the same address, we discard one
	   of them heuristically.
	   The end result is a list of spans, in address order, with distinct starts.
	   Our sorted metavector has one record per indexed span.
	   Logically the content is a pointer to its ELF metadata *and* its type.
	   For spans that are in dynsym, it points to their dynsym entry.
	*/
	struct segment_metadata segments[];
};
#define FILE_META_DESCRIBES_EXECUTABLE(meta) \
	((meta)->l->l_name && (meta)->l->l_name[0] == '\0') /* FIXME: better test? */
#define STARTS_BITMAP_NWORDS_FOR_PHDR(ph) \
    (ROUND_UP((ph)->p_vaddr + (ph)->p_memsz, sizeof (void*)) - ROUND_DOWN((ph)->p_vaddr, sizeof (void*)) \
    / (sizeof (void*)))

inline 
ElfW(Sym) *__runt_files_get_symtab_by_idx(struct file_metadata *meta, ElfW(Half) i)
{
	if (meta->symtab && meta->symtabndx == i) return meta->symtab;
	else if (meta->dynsym && meta->dynsymndx == i) return meta->dynsym;
	return NULL;
}


void __runt_files_notify_load(void *handle, const void *load_site) __attribute__((visibility("protected")));
void __runt_files_notify_unload(const char *copied_filename) __attribute__((visibility("protected")));

const void *
__runt_find_section_boundary(
	unsigned char *search_addr,
	ElfW(Word) flags,
	_Bool backwards,
	struct file_metadata **out_fm,
	unsigned *out_shndx) __attribute__((visibility("protected")));

void __runt_segments_notify_define_segment(
	struct file_metadata *meta,
	unsigned phndx,
	unsigned loadndx
) __attribute__((visibility("protected")));
void __runt_sections_notify_define_section(
	struct file_metadata *meta,
	const ElfW(Shdr) *shdr
) __attribute__((visibility("protected")));

/* This is basically our supplement to the stuff we can access
 * from the struct link_map entries in the ld.so. There is some
 * duplication, mainly because we don't want to depend on impl-
 * -specific stuff in there. */
#define _sym_or_reloc_kind(v, last_v) \
 v(REC_DYNSYM, 0) /* in the dynsym of the base object */ \
 v(REC_EXTRASYM, 1) /* extra symbols in the meta-object, generated by tools/extrasyms */ \
 v(REC_SYMTAB, 2) /* in the (static) symtab of the base object */ \
 v(REC_RELOC, 4) /* in the relocs of the base object (maybe now stripped) -- *must be ==4* and the only enumerator having the third bit set */ \
 last_v(REC_UNKNOWN, 0x8000)
#define _sym_or_reloc_kind_v(tok, n) tok = n,
#define _sym_or_reloc_kind_last_v(tok, n) tok = n
enum sym_or_reloc_kind
{
	_sym_or_reloc_kind(_sym_or_reloc_kind_v, _sym_or_reloc_kind_last_v)
};
#undef _sym_or_reloc_kind_v
#undef _sym_or_reloc_kind_last_v
/* We can pack all this into a single 64-bit word. But we can't declare
 * such structs statically in C, because we lack the relocs for the 44-bit
 * pointer field. We can do it in assembly, by factoring the 'kind' and 
 * 'idx' into the addend.
 *
 * Is this optimisation worth it? Potentially yes. We have one of these
 * records for every distinct string literal. Spending 16 bytes on each
 * could easily waste hundreds of kilobytes. These are not shareable
 * between processes. */
struct sym_only_rec
{
	unsigned kind:3; // an instance of sym_or_reloc_kind
	unsigned long uniqtype_ptr_bits_no_lowbits:44; // an address whose low-order 3 bits are 0
	unsigned idx:17; // at most 128K symbols of each kind, per segment
};
#define SYM_ONLY_REC_WORD(kind, idx_as_unsigned_long, ptr_as_integer_incl_lowbits) \
	(((idx_as_unsigned_long) << 47) + (ptr_as_integer_incl_lowbits) + ((kind) & 0x7))
/* We no longer map reloc records at run time. Instead, we pack both
 * the base address and the size into a single word. */
struct reloc_only_rec
{
	unsigned is_reloc:1; // if kind==REC_RELOC, means (uniquely) the top bit is set
	unsigned size:31; // reloc targets are at most 2GB in size
	unsigned long base_vaddr:32; // reloc targets must live in first 4GB of DSO's addr space
};
#define RELOC_ONLY_REC_WORD(base_vaddr, size) \
	( ((base_vaddr) << 32) | (((size) & ((1ul<<31)-1)) << 1) | 1ul)
union sym_or_reloc_rec
{
	unsigned is_reloc:1;
	struct sym_only_rec sym;
	struct reloc_only_rec reloc;
};

#ifdef _GNU_SOURCE /* We use the GNU C "statement expressions" extension */
/* Macro which open-codes a binary search over a sorted array
 * of T, returning a pointer to the highest element that
 * is greater than or equal to the target. To get an integer
 * value out of a T t, we use proj(t). */
#define /* T* */  bsearch_leq_generic(T, target_proj_val, /*  T*  */ base, /* unsigned */ n, proj) \
	({ \
		T *upper = base + n; \
		T *lower = base; \
		if (upper - lower == 0) abort(); \
		assert(proj(lower) <= target_proj_val); \
		while (upper - lower != 1) \
		{ \
			T *mid = lower + ((upper - lower) / 2); \
			if (proj(mid) > target_proj_val) \
			{ \
				/* we should look in the lower half */ \
				upper = mid; \
			} \
			else lower = mid; \
		} \
		assert(proj(lower) <= target_proj_val); \
		/* if we didn't hit the max item, assert the next one is greater */ \
		assert(lower == base + n - 1 \
			 || proj(lower+1) > target_proj_val); \
		/* If all elements are > the target, return NULL */ \
		proj(lower) <= target_proj_val ? lower : NULL; \
	})
#endif

static inline uintptr_t vaddr_from_rec(union sym_or_reloc_rec *p,
	struct file_metadata *file)
{
	ElfW(Sym) *symtab;
	if (p->is_reloc) return p->reloc.base_vaddr;
	else switch (p->sym.kind)
	{
		case REC_DYNSYM:   symtab = file->dynsym; goto sym;
		case REC_SYMTAB:   symtab = file->symtab; goto sym;
		case REC_EXTRASYM: symtab = file->extrasym; goto sym;
		sym:
			return symtab[p->sym.idx].st_value;
		default: abort();
	}
}

#endif
